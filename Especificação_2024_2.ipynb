{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alekswheeler/datasci_home_work/blob/main/Especifica%C3%A7%C3%A3o_2024_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFTJh1VJhXQO"
      },
      "source": [
        "# Trabalho Prático"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okgk7zc4h-OH"
      },
      "source": [
        "O objetivo geral deste trabalho é praticar os conceitos discutidos em sala de aula, principalmente: representação e pré-processamento de dados textuais; redução de dimensionalidade e algoritmos de agrupamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFEpZjjhcqH"
      },
      "source": [
        "## Conjunto de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28ezm41sjRx9"
      },
      "source": [
        "Para esse trabalho utilizaremos um conjunto de dados de filmes. Os dados foram obtidos de várias fontes, incluindo IMDB.\n",
        "\n",
        "O conjunto de dados que vocês deverão usar encontra-se no AVA da disciplina. Os dados estão organizados um arquivo (`.csv`) com as seguintes colunas:\n",
        "\n",
        "* **genres** - gêneros a que um filme pertence. Veja que um filme pode estar associado a mais de um gênero (`str`);\n",
        "* **sinopse** - sinopse do filme (`str`);\n",
        "* **startYear** - ano de lançamento do filme (`int`);\n",
        "* **primaryTitle** - título do filme (`str`);\n",
        "* **runtimeMinutes** - duração do filme, em minutos (`int`);\n",
        "* **averageRating** - média das avaliações do filme (`float`);\n",
        "* **numVotes** - número de avaliações do filme (`int`);\n",
        "* **actors_names** - atores/atrizes principais (`str`);\n",
        "* **directors_names** - diretores(as) do filme (`str`).\n",
        "\n",
        "**Observação:** esse conjunto de dados é uma versão transformada dos dados originais. Por exemplo, gêneros muito populares ou raros foram removidos.\n",
        "\n",
        "**ATENÇÃO**\n",
        "É possível que seu computador não consiga lidar com o conjunto de dados completo. Se for o caso, faça uma amostra aleatória de filmes do conjunto de dados. Deixe claro o processo de amostragem, o tamanho das amostras finais que considerou no trabalho e as especificações do computador utilizado."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os comandos abaixo mostram como os dados podem ser obtidos e carregados em um `DataFrame`."
      ],
      "metadata": {
        "id": "JUwkY_E-lD5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1AeYgV89TmYvNC__RDXr8hS0P6WOsChWg' -O filmes.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "z5tkfAI0OIrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7fd1a56-45f9-48df-dde3-c328c8ccc9ed"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-08 00:31:40--  https://docs.google.com/uc?export=download&id=1AeYgV89TmYvNC__RDXr8hS0P6WOsChWg\n",
            "Resolving docs.google.com (docs.google.com)... 209.85.200.101, 209.85.200.102, 209.85.200.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|209.85.200.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1AeYgV89TmYvNC__RDXr8hS0P6WOsChWg&export=download [following]\n",
            "--2025-02-08 00:31:40--  https://drive.usercontent.google.com/download?id=1AeYgV89TmYvNC__RDXr8hS0P6WOsChWg&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 64.233.181.132, 2607:f8b0:4001:c09::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|64.233.181.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11380332 (11M) [application/octet-stream]\n",
            "Saving to: ‘filmes.csv’\n",
            "\n",
            "filmes.csv          100%[===================>]  10.85M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-02-08 00:31:47 (157 MB/s) - ‘filmes.csv’ saved [11380332/11380332]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpZGHWs7p0C2"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"filmes.csv\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "a = df['sinopse']"
      ],
      "metadata": {
        "id": "hrQlXDHxzl9r"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "D = [\"É escória échange\", \"this is 1980  a another people and\", \"example example example\"]\n",
        "\n",
        "vectorizer = TfidfVectorizer(token_pattern=r'\\b[a-zA-ZÀ-ÖØ-öø-ÿ]+\\b', stop_words='english')\n",
        "vectorizer.fit_transform(D)\n",
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "Xpx94zrcBg3T",
        "outputId": "16bcee11-ee3d-43a0-fe1e-eac251e126cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['escória', 'example', 'people', 'é', 'échange'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRqKIFG8oOjC"
      },
      "source": [
        "## Objetivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPvGwYn7oOjC"
      },
      "source": [
        "Vocês deverão utilizar aprendizado não supervisionado (neste caso, agrupamento) para investigar se há relação entre a **sinopse** de um filme e o(s) **gênero(s)** a que pertence.\n",
        "\n",
        "De forma mais específica, vocês deverão agrupar os filmes de acordo suas sinopses e, após isso, verificar a distribuição dos gêneros em cada grupo. Ou seja, se os filmes pertencentes ao mesmo grupo possuem o(s) mesmo(s) gênero(s) ou se as distribuições de gêneros de grupos diferentes são distintas."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trabalho"
      ],
      "metadata": {
        "id": "HnmmtUKU6iy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de fazer o pré-processamento de dados a ideia é que vamos dividir a base de dados em pedaços menores mantendo a proporção da base de dados original ([StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html))."
      ],
      "metadata": {
        "id": "JrWBVR_nwBSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['genres'])\n",
        "y = df['genres']"
      ],
      "metadata": {
        "id": "6nCJt4sZ4gHN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Dividindo em 10 Folds estratificados\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "# Guardar todos os folds\n",
        "folds = list(skf.split(X, y))\n",
        "\n",
        "# Escolher um fold aleatório\n",
        "random_fold = np.random.RandomState(SEED).choice(len(folds))\n",
        "\n",
        "# Separar os dados do fold escolhido\n",
        "train_idx, test_idx = folds[random_fold]\n",
        "rand_X, rand_y = X.iloc[test_idx], y.iloc[test_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2kowOGD4p2i",
        "outputId": "d4ea0509-845c-48b1-85cc-063bc8a09fe5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pegando apenas a característica sinopse da amostra\n",
        "rand_X = rand_X['sinopse']"
      ],
      "metadata": {
        "id": "7fn4hVBa9lUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando matriz de tokens para trabalhar com TF-IDF"
      ],
      "metadata": {
        "id": "EJiupFZI-VrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Criando o vetor TF-IDF\n",
        "vectorizer = TfidfVectorizer(token_pattern=r'\\b[a-zA-ZÀ-ÖØ-öø-ÿ]+\\b'\n",
        "                              , stop_words='english'\n",
        "                              , strip_accents='unicode')\n",
        "\n",
        "# Ajusta o vectorizer no conjunto completo (ou apenas no treino, se preferir)\n",
        "vectorizer.fit(rand_X)\n",
        "\n",
        "# Transforma os dados de rand_X\n",
        "rand_X_tfidf = vectorizer.transform(rand_X)\n",
        "\n",
        "tfidf_dataframe = pd.DataFrame(rand_X_tfidf.todense(), columns = vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "lZeO60x1-Wbp"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.get_feature_names_out()[500:900]\n",
        "# tfidf_dataframe.info()"
      ],
      "metadata": {
        "id": "TxgisCAmJbMD",
        "outputId": "59ce5dba-b757-48ff-ad34-e5f5164d9f49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['akunin', 'al', 'alabado', 'alabama', 'aladdin', 'alain',\n",
              "       'alakananda', 'alamaara', 'alan', 'alarm', 'alarming', 'alas',\n",
              "       'alaska', 'alaskan', 'alba', 'albania', 'albanian', 'albeit',\n",
              "       'albert', 'alberta', 'albertina', 'alberto', 'albino', 'albion',\n",
              "       'albright', 'album', 'albums', 'alcatraz', 'alchemic', 'alchemist',\n",
              "       'alchemy', 'alcohol', 'alcoholic', 'alcoholism', 'aldaniti',\n",
              "       'aldin', 'aldo', 'alebrije', 'alecia', 'alee', 'alegre',\n",
              "       'alejandra', 'alejandro', 'aleksander', 'aleksandr', 'aleksey',\n",
              "       'alekseyevna', 'alemao', 'alerted', 'alerts', 'alessandra',\n",
              "       'alessandro', 'alev', 'alex', 'alexander', 'alexanderplatz',\n",
              "       'alexandra', 'alexandre', 'alexei', 'alexey', 'alexis', 'alfaro',\n",
              "       'alfonso', 'alfred', 'alfredo', 'alfredsson', 'algae', 'algebra',\n",
              "       'algeria', 'algerian', 'ali', 'alia', 'alias', 'alibi', 'alibis',\n",
              "       'alibrandi', 'alice', 'alicia', 'alicja', 'alien', 'alienated',\n",
              "       'alienating', 'aliens', 'alig', 'aligned', 'aligns', 'alija',\n",
              "       'alik', 'alike', 'alikes', 'alimony', 'alina', 'aline', 'alisa',\n",
              "       'alison', 'alive', 'alizeh', 'allah', 'allan', 'allay',\n",
              "       'allegations', 'alleged', 'allegedly', 'alleges', 'allegiance',\n",
              "       'allegory', 'allen', 'allende', 'allergies', 'allergy',\n",
              "       'alleviate', 'alley', 'alleys', 'alliance', 'allie', 'allied',\n",
              "       'allies', 'alligator', 'alligators', 'allign', 'allison', 'allow',\n",
              "       'allowance', 'allowed', 'allowing', 'allows', 'allred', 'allure',\n",
              "       'allured', 'alluring', 'ally', 'alma', 'almamarik', 'almanac',\n",
              "       'almighty', 'almshouses', 'alois', 'alongside', 'aloof', 'aloshi',\n",
              "       'aloud', 'alpagueur', 'alpha', 'alpine', 'alpinist', 'alps', 'als',\n",
              "       'alsmeden', 'alt', 'altai', 'altamira', 'altar', 'alter',\n",
              "       'altercation', 'altered', 'altering', 'alternate', 'alternates',\n",
              "       'alternations', 'alternative', 'alters', 'alto', 'altruistic',\n",
              "       'alumni', 'alumnus', 'alvarado', 'alvares', 'alvarez', 'alvin',\n",
              "       'alwood', 'alyonushka', 'alyosha', 'alyssa', 'alzheimer',\n",
              "       'amacord', 'amadeus', 'amado', 'amador', 'amaia', 'amala',\n",
              "       'amalie', 'amalric', 'aman', 'amanda', 'amando', 'amar', 'amara',\n",
              "       'amarendra', 'amarilly', 'amaryllis', 'amassed', 'amateur',\n",
              "       'amateurism', 'amateurs', 'amato', 'amatuer', 'amazed', 'amazing',\n",
              "       'amazingly', 'amazon', 'amazons', 'ambala', 'ambassador',\n",
              "       'ambassadors', 'amber', 'ambiguous', 'ambition', 'ambitions',\n",
              "       'ambitious', 'ambitiously', 'ambivalent', 'ambler', 'amboss',\n",
              "       'ambray', 'ambrose', 'ambrosio', 'ambush', 'ambushed', 'ambushes',\n",
              "       'ambushing', 'ameche', 'amelia', 'amenable', 'amend', 'amends',\n",
              "       'amenta', 'america', 'american', 'americans', 'americo', 'amerigo',\n",
              "       'amerikkka', 'ametani', 'ami', 'amiable', 'amid', 'amidst',\n",
              "       'amies', 'amigo', 'amigos', 'amina', 'amir', 'amiss', 'amituanai',\n",
              "       'amityville', 'ammar', 'ammo', 'ammunition', 'amna', 'amnesia',\n",
              "       'amnesiac', 'amnesty', 'amo', 'amok', 'amontillado', 'amor',\n",
              "       'amoral', 'amornsupasiri', 'amorous', 'amoruso', 'amory', 'amos',\n",
              "       'amounting', 'amounts', 'amour', 'amoureux', 'amphibious', 'ample',\n",
              "       'amplifies', 'amplify', 'amputee', 'amrita', 'amstell',\n",
              "       'amsterdam', 'amudha', 'amulet', 'amundsen', 'amusement',\n",
              "       'amusements', 'amusing', 'amy', 'ana', 'anabel', 'anabelle',\n",
              "       'analogous', 'analysis', 'analyst', 'analyze', 'analyzes', 'anand',\n",
              "       'anansa', 'ananth', 'anarchic', 'anarchist', 'anarchistic',\n",
              "       'anarchists', 'anarchy', 'anastasia', 'anatolian', 'anatoly',\n",
              "       'ancestor', 'ancestors', 'ancestral', 'anchor', 'anchors',\n",
              "       'ancient', 'andaman', 'anders', 'andersen', 'anderson',\n",
              "       'andersson', 'andes', 'andhra', 'andi', 'andre', 'andrea',\n",
              "       'andreas', 'andree', 'andrei', 'andres', 'andrew', 'andrews',\n",
              "       'andrey', 'andrieux', 'andriotti', 'android', 'androids',\n",
              "       'andrzej', 'andy', 'ane', 'anedda', 'anesthesia', 'anew', 'anezka',\n",
              "       'ang', 'angamaly', 'ange', 'angel', 'angela', 'angeles', 'angeli',\n",
              "       'angelic', 'angelica', 'angelina', 'angeline', 'angelino',\n",
              "       'angelique', 'angelo', 'angels', 'anger', 'angered', 'angering',\n",
              "       'angers', 'anges', 'angie', 'anglo', 'anglophone', 'angola',\n",
              "       'angono', 'angry', 'angst', 'anguish', 'anil', 'animal',\n",
              "       'animalistic', 'animals', 'animate', 'animated', 'animates',\n",
              "       'animation', 'animatronic', 'anime', 'animeigo', 'animosity',\n",
              "       'anirudh', 'anita', 'anitha', 'anja', 'anjali', 'ankle',\n",
              "       'ankylosaurus', 'ann', 'anna', 'annabelle', 'annamayya', 'annas',\n",
              "       'anne', 'annette', 'anni', 'annie', 'annihilate', 'annihilating',\n",
              "       'annihilation', 'anniversary', 'announce', 'announced',\n",
              "       'announces', 'announcing', 'annoy', 'annoyance'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar o Stemming Vide Código em outro notebook"
      ],
      "metadata": {
        "id": "olC8kEGxMCpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Antes de discutir algumas construções de $\\mathbf{X}$, veremos algumas tarefas iniciais de limpeza e pré-processamento de textos.\n",
        "\n",
        "**Essas tarefas não são simples, e a lista a seguir não é exaustiva**.\n",
        "Para essa aula, estou seguindo algumas dicas de https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
        "\n",
        "É uma boa prática seguir, ao menos, os seguintes passos:\n",
        "1. Dividir o texto em *tokens*\n",
        "2. Converter o texto para letras minúsculas\n",
        "3. Remover símbolos de pontuação de cada *token*\n",
        "4. Converter caracteres especiais (passo discutível e necessidade deve ser analisada)\n",
        "5. Remover *tokens* que não são palavras\n",
        "6. Remover *tokens* que são *stop words*\n",
        "\n",
        "Além disso, as seguintes operações podem ser úteis em algumas situações:\n",
        "7. *stemming*\n",
        "8. *lemmatization* (disponível em algumas bibliotecas, mas não vou falar sobre)\n"
      ],
      "metadata": {
        "id": "AkDI2r5knjOg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0vUwb8UrwAJQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq1Vt0c9hoPa"
      },
      "source": [
        "## Metodologia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akm5BHH7wkKX"
      },
      "source": [
        "Para atingir o objetivo proposto, vocês deverão seguir ao menos os seguintes passos:\n",
        "1. Pré-processamento dos dados textuais;\n",
        "2. Construção da matriz de TF-IDF;\n",
        "3. Redução de dimensionalidade, via PCA (Leia também sobre o *Truncated SVD*: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html);\n",
        "4. Aplicação de ao menos dois algoritmos de agrupamento vistos na disciplina;\n",
        "5. Validação da metodologia utilizada;\n",
        "6. Interpretação dos resultados.\n",
        "\n",
        "**PS:** essas são as exigências mínimas. Caso vocês queiram fazer/propor algo extra, será permitido (e pode ajudar na nota se a proposta for relevante)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-yvMFikhq_X"
      },
      "source": [
        "## Resultados esperados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecXkqcTOzuTk"
      },
      "source": [
        "Dois tipo de resultados são esperados: validação e análise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPMymRAQz6Og"
      },
      "source": [
        "### Resultados de validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR2SWoRYz-xS"
      },
      "source": [
        "O trabalho deve conter resultados mostrando que os algoritmos (e respectivos parâmetros) foram escolhidos e utilizados de forma correta. Entre os pontos importantes:\n",
        "1. Como foi escolhido o número de componentes principais para o PCA? O número de componentes principais tem um impacto significativo nos resultados? É necessário usar PCA neste trabalho?\n",
        "2. Como o número de grupos para cada algoritmo de agrupamento foi definido? A escolha do algoritmo de agrupamento impacta significativamente os resultados? E o número de grupos?\n",
        "\n",
        "Fará parte da avaliação a forma que escolherem para validar a metodologia. Vocês podem recorrer a visualizações interessantes, medidas internas..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEz5n3-50Lsx"
      },
      "source": [
        "### Análise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYodSngv0NZg"
      },
      "source": [
        "Após validar e entender os resultados (e se convencerem que estão corretos e fazem sentido), você deve responder as perguntas principais:\n",
        "- Há diferença nas distribuições de gêneros dos filmes em grupos diferentes?\n",
        "- Há relação entre as sinopses dos filmes e os respectivos gêneros?\n",
        "\n",
        "- **Opcional, pontuação extra:** se, além das sinopses, você também considerar as demais informações no conjunto de dados (avaliações, atores/atrizes, diretores(as), título, ano e duração) para os algoritmos de agrupamento, é possível encontrar uma melhor associação entre os grupos e os gêneros dos filmes?\n",
        "Novamente, recorra às ferramentas que já vimos no curso para responder essa pergunta: visualizações, medidas externas... **soluções que tiverem achados interessantes nessa parte do trabalho ganharão ponto extra**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ASld2-huE3"
      },
      "source": [
        "## Observações importantes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UO36M8FpCRw"
      },
      "source": [
        "1. Durante a fase de agrupamento, apenas a informação da sinopse deve ser utilizada. A informação de **gênero dos filmes** deve ser usada apenas após a fase de agrupamento para validar e analisar os resultados.\n",
        "2. Vocês podem usar todas as bibliotecas Python que venho mostrando em aula. Caso queiram usar algo muito diferente (por exemplo, alguma biblioteca de uso comercial), perguntem ao professor antes (em nosso fórum do AVA).\n",
        "3. Lembrem-se que este trabalho vale 30% da nota do semestre. Vocês serão avaliados pela:\n",
        "  - Qualidade dos resultados quantitativos;\n",
        "  - Escolha e condução da metodologia;\n",
        "  - Uso de visualizações informativas e bem feitas;\n",
        "  - Explicação dos passos seguidos e das decisões tomadas;\n",
        "  - Justificativas para as decisões tomadas;\n",
        "  - Análise dos resultados;\n",
        "  - Conclusões.\n",
        "4. Qualquer colaboração, entre grupos ou de fontes externas, deve ser citada e mencionada no trabalho. **NÃO HAVERÁ TOLERÂNCIA PARA COLABORAÇÕES INDEVIDAS!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exsoCRlShxue"
      },
      "source": [
        "## Grupos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y2N5Z6z5hg2"
      },
      "source": [
        "- **Graduação:** até 3 pessoas\n",
        "- **Pós-graduação:** individual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FZB-sI2h5SD"
      },
      "source": [
        "## Entrega"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JoLe1135rh-"
      },
      "source": [
        "- **Linguagem de programação:** Python\n",
        "- **O que entregar:** um *Jupyter Notebook*, contendo texto, código e resultados. Deve ser possível que o professor execute o seu código, mas o arquivo ``.ipynb`` submetido já deve conter todos os resultados (i.e., deve ser possível corrigir seu trabalho apenas abrindo o arquivo). Apenas um integrante do grupo deve fazer a submissão no AVA. Lembrem-se de colocar a informação de todos os integrantes do grupo (nome, matrícula e e-mail)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euhJZNqK6jCI"
      },
      "source": [
        "## Dúvidas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKBfomkc6l8e"
      },
      "source": [
        "Postem em nosso fórum do AVA!"
      ]
    }
  ]
}